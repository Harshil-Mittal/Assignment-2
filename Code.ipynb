{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9zz6IK2Y_6jh"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ItWAYl7K_814",
    "outputId": "ebaca1ce-7663-4f33-c86b-f4212f2cf433"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heart.csv    age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
      "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
      "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
      "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
      "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
      "\n",
      "   ca  thal  target  \n",
      "0   2     3       0  \n",
      "1   0     3       0  \n",
      "2   0     3       0  \n",
      "3   1     3       0  \n",
      "4   3     2       0  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Data Acquisition\n",
    "# Load the Heart Disease UCI dataset\n",
    "data = pd.read_csv('heart.csv')\n",
    "print(\"heart.csv\", data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ErHmTr8b_-0Z"
   },
   "outputs": [],
   "source": [
    "# Step 2: Define Methodology and Objectives\n",
    "# Objective: Predict heart disease risk based on health metrics to support SDG 3.\n",
    "# Methodology: Explore data, preprocess, use classification models, and evaluate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VDP3XSt_Ao9i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values:\n",
      " age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n",
      "\n",
      "Missing Values:\n",
      " age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Data Preprocessing\n",
    "# 3.1 Check for missing values\n",
    "print(\"\\nMissing Values:\\n\", data.isnull().sum())\n",
    "\n",
    "# 3.3 Encode categorical variables if present\n",
    "data = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "# 3.2 Fill missing values with column medians\n",
    "data.fillna(data.median(), inplace=True)\n",
    "\n",
    "# 3.4 Separate features and target variable\n",
    "X = data.drop('target', axis=1)  # Features\n",
    "y = data['target']  # Target variable\n",
    "\n",
    "# Convert 'num' to binary classification: 0 (No disease), 1 (Disease)\n",
    "y = y.apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# 3.5 Handle class imbalance using SMOTE\n",
    "smote = SMOTE()\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "# 3.6 Standardize the features for better model performance\n",
    "scaler = StandardScaler()\n",
    "X_res = scaler.fit_transform(X_res)\n",
    "\n",
    "print(\"\\nMissing Values:\\n\", data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2zhX58izAGwN",
    "outputId": "c58c6946-6011-4de0-efff-f6fec32f045e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Validation Results (Accuracy):\n",
      "Logistic Regression - Accuracy: 0.85\n",
      "Decision Tree - Accuracy: 0.99\n",
      "Random Forest - Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Model Selection and Validation\n",
    "# Define models to evaluate\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier()\n",
    "}\n",
    "\n",
    "# Perform K-Fold Cross Validation to evaluate each model\n",
    "print(\"\\nModel Validation Results (Accuracy):\")\n",
    "for model_name, model in models.items():\n",
    "    scores = cross_val_score(model, X_res, y_res, cv=10, scoring='accuracy')\n",
    "    print(f\"{model_name} - Accuracy: {scores.mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed Model Evaluation:\n",
      "\n",
      "Logistic Regression Results:\n",
      "Accuracy: 0.84\n",
      "Precision: 0.83\n",
      "Recall: 0.89\n",
      "F1-Score: 0.86\n",
      "AUC Score: 0.93\n",
      "\n",
      "Decision Tree Results:\n",
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-Score: 1.00\n",
      "AUC Score: 1.00\n",
      "\n",
      "Random Forest Results:\n",
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-Score: 1.00\n",
      "AUC Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Comparing Results with Multiple Metrics\n",
    "# Split the data into train and test sets for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train and evaluate each model on the test set\n",
    "print(\"\\nDetailed Model Evaluation:\")\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred):.2f}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred):.2f}\")\n",
    "    print(f\"F1-Score: {f1_score(y_test, y_pred):.2f}\")\n",
    "    \n",
    "    # AUC Score - Only for models that support it\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "        print(f\"AUC Score: {roc_auc_score(y_test, y_proba):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Assuming your model variable is `model`\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(\u001b[43mmodel\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "# Assuming your model variable is `model`\n",
    "joblib.dump(model, 'model.pkl')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
